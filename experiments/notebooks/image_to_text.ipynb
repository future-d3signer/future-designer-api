{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible models to test for:\n",
    "\n",
    "- PaliGemma 3B - Google\n",
    "- Phi3.5-Vision 4B - Microsoft\n",
    "- Lllama 3.2 7B - Meta\n",
    "- Molmo 7B-D, 7B-O - AllenAI\n",
    "- Qwen VL2 7B - Qwen\n",
    "\n",
    "\n",
    "Possible features:\n",
    "\n",
    "- Style:\n",
    "\n",
    "    Overall design style (e.g., modern, traditional, rustic, industrial, mid-century modern)\n",
    "    Specific style elements (e.g., tufted, skirted, wingback for chairs)\n",
    "\n",
    "- Color:\n",
    "\n",
    "    Primary color\n",
    "    Secondary colors or color combinations\n",
    "    Finish type (e.g., matte, glossy, distressed)\n",
    "\n",
    "- Material:\n",
    "\n",
    "    Main material (e.g., wood, metal, leather, fabric, glass)\n",
    "    Secondary materials\n",
    "    For fabrics: texture or pattern (e.g., smooth, woven, floral print)\n",
    "\n",
    "- Shape and Form:\n",
    "\n",
    "    Overall shape (e.g., rectangular, curved, L-shaped for sofas)\n",
    "    Distinctive features (e.g., high back, rolled arms, tapered legs)\n",
    "\n",
    "- Size:\n",
    "\n",
    "    Approximate dimensions or size category (e.g., small, medium, large)\n",
    "    Number of seats for seating furniture\n",
    "\n",
    "- Function:\n",
    "\n",
    "    Type of furniture (e.g., chair, sofa, table, bed)\n",
    "    Specific subcategory (e.g., dining chair, lounge chair, accent chair)\n",
    "\n",
    "- Details and Embellishments:\n",
    "\n",
    "    Decorative elements (e.g., nailhead trim, carved details, button tufting)\n",
    "    Hardware style (e.g., brass knobs, stainless steel legs)\n",
    "\n",
    "\n",
    "Use bigger model to generate catpions for images in dataset and then fine-tune smaller model with that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paligemma Experiments\n",
    "\n",
    "https://huggingface.co/google/paligemma-3b-mix-448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s464915/.conda/envs/fude/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading shards: 100%|██████████| 2/2 [08:04<00:00, 242.42s/it]\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "\n",
    "model_id = \"google/paligemma-3b-mix-448\"\n",
    "device = \"cuda:0\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device,\n",
    "    revision=\"bfloat16\",\n",
    ").eval()\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts:\n",
    "\n",
    "- caption color one word - returns color of object\n",
    "- caption design style - returns style of object\n",
    "- caption material that object is made of  - returns material (kinda bad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Bainton 110 Upholstered Sofa_1.jpg\n",
      "Caption: leather\n",
      "Processing time: 0.14 seconds\n",
      "--------------------\n",
      "Image: Clifford Upholstered Armchair_1.jpg\n",
      "Caption: wood\n",
      "Processing time: 0.12 seconds\n",
      "--------------------\n",
      "Image: Offline Outdoor Lounge Chair_1.jpg\n",
      "Caption: wood\n",
      "Processing time: 0.13 seconds\n",
      "--------------------\n",
      "Image: Miller Upholstered Armchair_1.jpg\n",
      "Caption: wood\n",
      "Processing time: 0.13 seconds\n",
      "--------------------\n",
      "Image: Cache Lounge Chair_5.jpg\n",
      "Caption: metal\n",
      "Processing time: 0.13 seconds\n",
      "--------------------\n",
      "Image: Bobbie 98 Upholstered Sofa_3.jpg\n",
      "Caption: wood\n",
      "Processing time: 0.12 seconds\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "##url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n",
    "image_folder = \"/home/s464915/future-designer/experiments/images\"\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        prompt = \"caption material that object is made of\"\n",
    "    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        model_inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(model.device)\n",
    "        input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            generation = model.generate(**model_inputs, max_new_tokens=30, do_sample=False)\n",
    "            generation = generation[0][input_len:]\n",
    "            decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "        \n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate and print the processing time\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Image: {filename}\")\n",
    "        print(f\"Caption: {decoded}\")\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi-3.5-vision Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-vision-instruct:\n",
      "- configuration_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-vision-instruct:\n",
      "- modeling_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Downloading shards: 100%|██████████| 2/2 [01:22<00:00, 41.29s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-vision-instruct:\n",
      "- processing_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/home/s464915/.conda/envs/fude/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:517: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoProcessor \n",
    "\n",
    "model_id = \"microsoft/Phi-3.5-vision-instruct\" \n",
    "\n",
    "# Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_id, \n",
    "  device_map=\"cuda\", \n",
    "  trust_remote_code=True, \n",
    "  torch_dtype=\"auto\", \n",
    "  _attn_implementation='eager'    \n",
    ")\n",
    "\n",
    "# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "processor = AutoProcessor.from_pretrained(model_id, \n",
    "  trust_remote_code=True, \n",
    "  num_crops=16\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Bainton 110 Upholstered Sofa_1.jpg\n",
      "Caption: {\n",
      "    \"type\": \"Sofa\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"White\",\n",
      "    \"material\": \"Leather\",\n",
      "    \"shape\": \"L\",\n",
      "    \"size\": \"Medium\",\n",
      "    \"details\": \"N/A\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Processing time: 4.19 seconds\n",
      "--------------------\n",
      "Image: Clifford Upholstered Armchair_1.jpg\n",
      "Caption: {\n",
      "    \"type\": \"Chair\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Multicolored\",\n",
      "    \"material\": \"Upholstered\",\n",
      "    \"shape\": \"Armchair\",\n",
      "    \"size\": \"Medium\",\n",
      "    \"details\": \"Striped pattern\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Processing time: 4.57 seconds\n",
      "--------------------\n",
      "Image: Offline Outdoor Lounge Chair_1.jpg\n",
      "Caption: {\n",
      "    \"type\": \"Chair\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Black\",\n",
      "    \"material\": \"Metal\",\n",
      "    \"shape\": \"Rectangular\",\n",
      "    \"size\": \"Medium\",\n",
      "    \"details\": \"Wooden slats\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Processing time: 4.46 seconds\n",
      "--------------------\n",
      "Image: Miller Upholstered Armchair_1.jpg\n",
      "Caption: {\n",
      "    \"type\": \"Chair\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Orange\",\n",
      "    \"material\": \"Leather\",\n",
      "    \"shape\": \"Armchair\",\n",
      "    \"size\": \"Small\",\n",
      "    \"details\": \"N/A\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Processing time: 4.43 seconds\n",
      "--------------------\n",
      "Image: Cache Lounge Chair_5.jpg\n",
      "Caption: {\n",
      "    \"type\": \"Sofa\",\n",
      "    \"style\": \"Contemporary\",\n",
      "    \"color\": \"Gray\",\n",
      "    \"material\": \"Upholstered fabric\",\n",
      "    \"shape\": \"Lounge\",\n",
      "    \"size\": \"Medium\",\n",
      "    \"details\": \"Metal frame\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Processing time: 4.65 seconds\n",
      "--------------------\n",
      "Image: Bobbie 98 Upholstered Sofa_3.jpg\n",
      "Caption: {\n",
      "    \"type\": \"Sofa\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"White\",\n",
      "    \"material\": \"Fabric\",\n",
      "    \"shape\": \"L\",\n",
      "    \"size\": \"Medium\",\n",
      "    \"details\": \"N/A\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Processing time: 4.30 seconds\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a furniture expert. Analyze the image and provide a detailed description in JSON format.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "<|image_1|>\n",
    "Describe the furniture in the image using the following JSON structure. Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
    "\n",
    "{\n",
    "    \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
    "    \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
    "    \"color\": \"Main color\",\n",
    "    \"material\": \"Primary material\",\n",
    "    \"shape\": \"General shape\",\n",
    "    \"size\": \"Size category (small, medium, large)\",\n",
    "    \"details\": \"Any decorative features\"\n",
    "    \"condition\": \"Apparent condition if relevant\"\n",
    "}\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "        prompt = processor.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        inputs = processor(prompt, image, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "        generation_args = { \n",
    "            \"max_new_tokens\": 1000, \n",
    "            \"temperature\": 0.0, \n",
    "            \"do_sample\": False, \n",
    "        } \n",
    "\n",
    "        generate_ids = model.generate(**inputs, \n",
    "            eos_token_id=processor.tokenizer.eos_token_id, \n",
    "            **generation_args\n",
    "        )\n",
    "\n",
    "        # remove input tokens \n",
    "        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "        response = processor.batch_decode(generate_ids, \n",
    "        skip_special_tokens=True, \n",
    "        clean_up_tokenization_spaces=False)[0] \n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate and print the processing time\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Image: {filename}\")\n",
    "        print(f\"Caption: {response}\")\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molmo Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s464915/.conda/envs/fude/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# load the processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/home/s464915/future-designer/experiments/images\"\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # process the image and text\n",
    "        inputs = processor.process(\n",
    "            images=[image],\n",
    "            text=\"Describe this image.\"\n",
    "        )\n",
    "\n",
    "        # move inputs to the correct device and make a batch of size 1\n",
    "        inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "        \n",
    "    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # generate output; maximum 200 new tokens; stop generation when <|endoftext|> is generated\n",
    "        output = model.generate_from_batch(\n",
    "            inputs,\n",
    "            GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "            tokenizer=processor.tokenizer\n",
    "        )\n",
    "\n",
    "        # only get generated tokens; decode them to text\n",
    "        generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "        generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate and print the processing time\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Image: {filename}\")\n",
    "        print(f\"Caption: {generated_text}\")\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen VL2 7b Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef790d02fa5c4f60914a79c8fa53589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load the model in half-precision on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "     attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Bainton 110 Upholstered Sofa_1.jpg\n",
      "Caption: ['{\\n    \"type\": \"Sofa\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Light gray\",\\n    \"material\": \"Leather\",\\n    \"shape\": \"Boxy\",\\n    \"size\": \"Large\",\\n    \"details\": \"Clean lines, minimalistic design\",\\n    \"condition\": \"New\"\\n}']\n",
      "Processing time: 3.00 seconds\n",
      "--------------------\n",
      "Image: Clifford Upholstered Armchair_1.jpg\n",
      "Caption: ['{\\n    \"type\": \"Chair\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Multicolored\",\\n    \"material\": \"Fabric\",\\n    \"shape\": \"Square\",\\n    \"size\": \"Medium\",\\n    \"details\": \"Striped pattern\",\\n    \"condition\": \"New\"\\n}']\n",
      "Processing time: 2.39 seconds\n",
      "--------------------\n",
      "Image: Offline Outdoor Lounge Chair_1.jpg\n",
      "Caption: ['{\\n    \"type\": \"Chair\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Dark gray\",\\n    \"material\": \"Metal\",\\n    \"shape\": \"U-shaped\",\\n    \"size\": \"Medium\",\\n    \"details\": \"Wooden slats\",\\n    \"condition\": \"New\"\\n}']\n",
      "Processing time: 2.42 seconds\n",
      "--------------------\n",
      "Image: orange_sofa.jpg\n",
      "Caption: ['{\\n    \"type\": \"Sofa\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Orange\",\\n    \"material\": \"Textile\",\\n    \"shape\": \"Rectangular\",\\n    \"size\": \"Large\",\\n    \"details\": \"Channel tufted\",\\n    \"condition\": \"New\"\\n}']\n",
      "Processing time: 2.48 seconds\n",
      "--------------------\n",
      "Image: Angus Coffee Table_1.jpg\n",
      "Caption: ['{\\n    \"type\": \"Table\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Gray\",\\n    \"material\": \"Marble\",\\n    \"shape\": \"Round\",\\n    \"size\": \"Medium\",\\n    \"details\": \"Pedestal base\",\\n    \"condition\": \"N/A\"\\n}']\n",
      "Processing time: 2.43 seconds\n",
      "--------------------\n",
      "Image: Miller Upholstered Armchair_1.jpg\n",
      "Caption: ['{\\n    \"type\": \"Chair\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Orange\",\\n    \"material\": \"Fabric\",\\n    \"shape\": \"Square\",\\n    \"size\": \"Medium\",\\n    \"details\": \"Wooden legs\",\\n    \"condition\": \"New\"\\n}']\n",
      "Processing time: 2.35 seconds\n",
      "--------------------\n",
      "Image: Circula Large Coffee Table_17.jpg\n",
      "Caption: ['{\\n    \"type\": \"table\",\\n    \"style\": \"modern\",\\n    \"color\": \"blue\",\\n    \"material\": \"metal\",\\n    \"shape\": \"round\",\\n    \"size\": \"medium\",\\n    \"details\": \"N/A\",\\n    \"condition\": \"N/A\"\\n}']\n",
      "Processing time: 2.35 seconds\n",
      "--------------------\n",
      "Image: empty-room-interior-for-gallery-exhibition-vector.jpg\n",
      "Caption: ['{\\n    \"type\": \"N/A\",\\n    \"style\": \"N/A\",\\n    \"color\": \"N/A\",\\n    \"material\": \"N/A\",\\n    \"shape\": \"N/A\",\\n    \"size\": \"N/A\",\\n    \"details\": \"N/A\",\\n    \"condition\": \"N/A\"\\n}']\n",
      "Processing time: 1.86 seconds\n",
      "--------------------\n",
      "Image: Ayres Coffee Table_8.jpg\n",
      "Caption: ['{\\n    \"type\": \"Coffee table\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Brown\",\\n    \"material\": \"Wood\",\\n    \"shape\": \"Rectangle\",\\n    \"size\": \"Medium\",\\n    \"details\": \"Drawer with rattan weave, open shelf, metal legs with wooden tips\",\\n    \"condition\": \"N/A\"\\n}']\n",
      "Processing time: 2.30 seconds\n",
      "--------------------\n",
      "Image: emptyroom1.jpg\n",
      "Caption: ['{\\n    \"type\": \"wardrobe\",\\n    \"style\": \"modern\",\\n    \"color\": \"white\",\\n    \"material\": \"wood\",\\n    \"shape\": \"vertical\",\\n    \"size\": \"large\",\\n    \"details\": \"N/A\",\\n    \"condition\": \"N/A\"\\n}']\n",
      "Processing time: 1.85 seconds\n",
      "--------------------\n",
      "Image: Cache Lounge Chair_5.jpg\n",
      "Caption: ['{\\n    \"type\": \"Chair\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Light gray\",\\n    \"material\": \"Fabric\",\\n    \"shape\": \"Square\",\\n    \"size\": \"Medium\",\\n    \"details\": \"Metal frame\",\\n    \"condition\": \"New\"\\n}']\n",
      "Processing time: 2.29 seconds\n",
      "--------------------\n",
      "Image: Bobbie 98 Upholstered Sofa_3.jpg\n",
      "Caption: ['{\\n    \"type\": \"Sofa\",\\n    \"style\": \"Modern\",\\n    \"color\": \"Ivory\",\\n    \"material\": \"Textured fabric\",\\n    \"shape\": \"Boxy\",\\n    \"size\": \"Medium\",\\n    \"details\": \"Wooden base\",\\n    \"condition\": \"New\"\\n}']\n",
      "Processing time: 2.49 seconds\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/home/s464915/future-designer/experiments/images\"\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        conversation = [\n",
    "             {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a furniture expert. Analyze the image and provide a detailed description in JSON format.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\", \"text\": \"\"\"Describe the furniture in the image using the following JSON structure. \n",
    "                                                Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
    "                            {\n",
    "                                \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
    "                                \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
    "                                \"color\": \"Main color\",\n",
    "                                \"material\": \"Primary material\",\n",
    "                                \"shape\": \"General shape\",\n",
    "                                \"size\": \"Size category (small, medium, large)\",\n",
    "                                \"details\": \"Any decorative features\"\n",
    "                                \"condition\": \"Apparent condition if relevant\"\n",
    "                            }\n",
    "                    \"\"\"},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        # Preprocess the inputs\n",
    "        text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "        # Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "        inputs = processor(\n",
    "            text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Inference: Generation of the output\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids) :]\n",
    "            for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "        ]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        \n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate and print the processing time\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Image: {filename}\")\n",
    "        print(f\"Caption: {output_text}\")\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen VL2 2b Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e28da8bb93f4ac08167ccf4793158cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "import time\n",
    "import os\n",
    "\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "\n",
    "# Load the model in half-precision on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "     attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Bainton 110 Upholstered Sofa_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"sofa\",\\n  \"style\": \"modern\",\\n  \"color\": \"light grey\",\\n  \"material\": \"leather\",\\n  \"shape\": \"two-seater\",\\n  \"size\": \"medium\",\\n  \"details\": \"no visible decorative features\"\\n}\\n```']\n",
      "Processing time: 2.55 seconds\n",
      "--------------------\n",
      "Image: Clifford Upholstered Armchair_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Multicolored\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Medium\",\\n  \"details\": \"No specific decorative features\"\\n}\\n```']\n",
      "Processing time: 2.02 seconds\n",
      "--------------------\n",
      "Image: Offline Outdoor Lounge Chair_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"N/A\",\\n  \"material\": \"Wood and metal\",\\n  \"shape\": \"Lounge chair\",\\n  \"size\": \"Medium\",\\n  \"details\": \"No specific decorative features\",\\n  \"condition\": \"N/A\"\\n}\\n```']\n",
      "Processing time: 2.30 seconds\n",
      "--------------------\n",
      "Image: orange_sofa.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Sofa\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Orange\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Large\",\\n  \"details\": \"No specific decorative features\"\\n}\\n```']\n",
      "Processing time: 2.03 seconds\n",
      "--------------------\n",
      "Image: Angus Coffee Table_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Table\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Gray\",\\n  \"material\": \"Marble\",\\n  \"shape\": \"Round\",\\n  \"size\": \"Medium\",\\n  \"details\": \"No visible decorative features\"\\n}\\n```']\n",
      "Processing time: 1.99 seconds\n",
      "--------------------\n",
      "Image: Miller Upholstered Armchair_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Orange\",\\n  \"material\": \"Velvet\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Medium\",\\n  \"details\": \"No visible decorative features\"\\n}\\n```']\n",
      "Processing time: 1.97 seconds\n",
      "--------------------\n",
      "Image: Circula Large Coffee Table_17.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Table\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Blue\",\\n  \"material\": \"Metal\",\\n  \"shape\": \"Round\",\\n  \"size\": \"Medium\",\\n  \"details\": \"No visible decorative features\"\\n}\\n```']\n",
      "Processing time: 1.94 seconds\n",
      "--------------------\n",
      "Image: empty-room-interior-for-gallery-exhibition-vector.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"N/A\",\\n  \"style\": \"N/A\",\\n  \"color\": \"N/A\",\\n  \"material\": \"N/A\",\\n  \"shape\": \"N/A\",\\n  \"size\": \"N/A\",\\n  \"details\": \"N/A\",\\n  \"condition\": \"N/A\"\\n}\\n```']\n",
      "Processing time: 1.82 seconds\n",
      "--------------------\n",
      "Image: Ayres Coffee Table_8.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Coffee table\",\\n  \"style\": \"Modern\",\\n  \"color\": \"N/A\",\\n  \"material\": \"Wood and metal\",\\n  \"shape\": \"Rectangular\",\\n  \"size\": \"Medium\",\\n  \"details\": \"Cane drawer and open shelf\",\\n  \"condition\": \"N/A\"\\n}\\n```']\n",
      "Processing time: 2.05 seconds\n",
      "--------------------\n",
      "Image: emptyroom1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Cabinet\",\\n  \"style\": \"Modern\",\\n  \"color\": \"White\",\\n  \"material\": \"Wood\",\\n  \"shape\": \"Shelving unit\",\\n  \"size\": \"Large\",\\n  \"details\": \"N/A\"\\n}\\n```']\n",
      "Processing time: 1.67 seconds\n",
      "--------------------\n",
      "Image: Cache Lounge Chair_5.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Light Grey\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Medium\",\\n  \"details\": \"No visible decorative features\"\\n}\\n```']\n",
      "Processing time: 1.98 seconds\n",
      "--------------------\n",
      "Image: Bobbie 98 Upholstered Sofa_3.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Sofa\",\\n  \"style\": \"Modern\",\\n  \"color\": \"White\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Medium\",\\n  \"details\": \"No visible decorative features\"\\n}\\n```']\n",
      "Processing time: 2.01 seconds\n",
      "--------------------\n",
      "Avg time of interface: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/home/s464915/future-designer/experiments/images\"\n",
    "times = []\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        conversation = [\n",
    "             {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a furniture expert. Analyze the image and provide a detailed description in JSON format.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"resized_height\": 280,\n",
    "                        \"resized_width\": 420\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\", \"text\": \"\"\"Describe the furniture in the image using the following JSON structure. \n",
    "                                                Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
    "                            {\n",
    "                                \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
    "                                \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
    "                                \"color\": \"Main color\",\n",
    "                                \"material\": \"Primary material\",\n",
    "                                \"shape\": \"General shape\",\n",
    "                                \"size\": \"Size category (small, medium, large)\",\n",
    "                                \"details\": \"Any decorative features\"\n",
    "                                \"condition\": \"Apparent condition if relevant\"\n",
    "                            }\n",
    "                    \"\"\"},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        # Preprocess the inputs\n",
    "        text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "        # Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "        inputs = processor(\n",
    "            text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Inference: Generation of the output\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids) :]\n",
    "            for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "        ]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        \n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate and print the processing time\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "        \n",
    "        print(f\"Image: {filename}\")\n",
    "        print(f\"Caption: {output_text}\")\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "print(f'Avg time of interface: {sum(times)/len(times):.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen VL2 AWQ 2b Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d5a6124751426aaa4027ad4f955ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  13%|#3        | 388M/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a1c59b1cc841bd9c9cf7473ec0be85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5ad2c0cf7c425b89adb382e642e8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcfb3433f27482b88542c2dcf099f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78e451335ce46c0a63adf74267ce2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f365973354489dbc283c6cf3087507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e89f0f33fd04fa3932264818b910061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7053321cfb9c46358c37f420ed1308ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54027745a2d24aec9713c0200c93f679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0548746555654176836cd7c34b458075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "import time\n",
    "import os\n",
    "\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "\n",
    "# Load the model in half-precision on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct-AWQ\",\n",
    "    torch_dtype=torch.float16,\n",
    "     attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct-AWQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Bainton 110 Upholstered Sofa_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\\n  \"style\": \"Modern\",\\n  \"color\": \"White\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Large\",\\n  \"details\": \"No decorative features\",\\n  \"condition\": \"Apparent condition\"\\n}\\n```']\n",
      "Processing time: 2.65 seconds\n",
      "--------------------\n",
      "Image: Clifford Upholstered Armchair_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Multicolored\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Small\",\\n  \"details\": \"Decorative features\"\\n}\\n```']\n",
      "Processing time: 2.10 seconds\n",
      "--------------------\n",
      "Image: Offline Outdoor Lounge Chair_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Natural wood\",\\n  \"material\": \"Teak\",\\n  \"shape\": \"Lounge\",\\n  \"size\": \"Large\",\\n  \"details\": \"No decorative features\"\\n}\\n```']\n",
      "Processing time: 2.11 seconds\n",
      "--------------------\n",
      "Image: orange_sofa.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Orange\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Rectangle\",\\n  \"size\": \"Large\",\\n  \"details\": \"Decorative armrests\",\\n  \"condition\": \"Apparent condition\"\\n}\\n```']\n",
      "Processing time: 2.74 seconds\n",
      "--------------------\n",
      "Image: Angus Coffee Table_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Coffee table\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Gray\",\\n  \"material\": \"Marble\",\\n  \"shape\": \"Round\",\\n  \"size\": \"Small\",\\n  \"details\": \"No decorative features\"\\n}\\n```']\n",
      "Processing time: 2.08 seconds\n",
      "--------------------\n",
      "Image: Miller Upholstered Armchair_1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Orange\",\\n  \"material\": \"Velvet\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Large\",\\n  \"details\": \"No decorative features\"\\n}\\n```']\n",
      "Processing time: 2.06 seconds\n",
      "--------------------\n",
      "Image: Circula Large Coffee Table_17.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Coffee table\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Blue\",\\n  \"material\": \"Metal\",\\n  \"shape\": \"Round\",\\n  \"size\": \"Large\",\\n  \"details\": \"No decorative features\"\\n}\\n```']\n",
      "Processing time: 2.05 seconds\n",
      "--------------------\n",
      "Image: empty-room-interior-for-gallery-exhibition-vector.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"N/A\",\\n  \"style\": \"N/A\",\\n  \"color\": \"N/A\",\\n  \"material\": \"N/A\",\\n  \"shape\": \"N/A\",\\n  \"size\": \"N/A\",\\n  \"details\": \"N/A\",\\n  \"condition\": \"N/A\"\\n}\\n```']\n",
      "Processing time: 2.34 seconds\n",
      "--------------------\n",
      "Image: Ayres Coffee Table_8.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Coffee table\",\\n  \"style\": \"Modern\",\\n  \"color\": \"N/A\",\\n  \"material\": \"Wood\",\\n  \"shape\": \"Rectangular\",\\n  \"size\": \"Medium\",\\n  \"details\": \"Cane drawer and metal legs\",\\n  \"condition\": \"Apparent condition\"\\n}\\n```']\n",
      "Processing time: 2.48 seconds\n",
      "--------------------\n",
      "Image: emptyroom1.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Cabinet\",\\n  \"style\": \"Modern\",\\n  \"color\": \"White\",\\n  \"material\": \"Wood\",\\n  \"shape\": \"Shelving\",\\n  \"size\": \"Large\",\\n  \"details\": \"No specific details\"\\n}\\n```']\n",
      "Processing time: 2.12 seconds\n",
      "--------------------\n",
      "Image: Cache Lounge Chair_5.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Chair\",\\n  \"style\": \"Modern\",\\n  \"color\": \"Light Gray\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Square\",\\n  \"size\": \"Small\",\\n  \"details\": \"No decorative features\"\\n}\\n```']\n",
      "Processing time: 2.05 seconds\n",
      "--------------------\n",
      "Image: Bobbie 98 Upholstered Sofa_3.jpg\n",
      "Caption: ['```json\\n{\\n  \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\\n  \"style\": \"Modern\",\\n  \"color\": \"White\",\\n  \"material\": \"Fabric\",\\n  \"shape\": \"Modern\",\\n  \"size\": \"Large\",\\n  \"details\": \"No decorative features\",\\n  \"condition\": \"Apparent condition if relevant\"\\n}\\n```']\n",
      "Processing time: 2.75 seconds\n",
      "--------------------\n",
      "Avg time of interface: 2.30 s\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/home/s464915/future-designer/experiments/images\"\n",
    "times = []\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        conversation = [\n",
    "             {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a furniture expert. Analyze the image and provide a detailed description in JSON format.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"resized_height\": 280,\n",
    "                        \"resized_width\": 420\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\", \"text\": \"\"\"Describe the furniture in the image using the following JSON structure. \n",
    "                                                Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
    "                            {\n",
    "                                \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
    "                                \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
    "                                \"color\": \"Main color\",\n",
    "                                \"material\": \"Primary material\",\n",
    "                                \"shape\": \"General shape\",\n",
    "                                \"size\": \"Size category (small, medium, large)\",\n",
    "                                \"details\": \"Any decorative features\"\n",
    "                                \"condition\": \"Apparent condition if relevant\"\n",
    "                            }\n",
    "                    \"\"\"},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        # Preprocess the inputs\n",
    "        text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "        # Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "        inputs = processor(\n",
    "            text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Inference: Generation of the output\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids) :]\n",
    "            for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "        ]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        \n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate and print the processing time\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "        \n",
    "        print(f\"Image: {filename}\")\n",
    "        print(f\"Caption: {output_text}\")\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "print(f'Avg time of interface: {sum(times)/len(times):.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InternVL2 2B Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c885dd6e964341b96d46a709f9efe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "conversation.py:   0%|          | 0.00/15.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2-2B:\n",
      "- conversation.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2-2B:\n",
      "- modeling_intern_vit.py\n",
      "- conversation.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/home/s464915/.conda/envs/fude/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3b69abfef24d36a7521fbf748c4813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.41G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "InternLM2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccfa189f4e54dc689e7fbfad45e2118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f764521f31a44d009504f7a4f04aac55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fd10a4224f45f6a55fb3ca2adc74d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_internlm2.py:   0%|          | 0.00/8.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2-2B:\n",
      "- tokenization_internlm2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35cb71e01ca46dba86b1abad42f6325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44964212b19a4bdd889b631cb85766b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/179 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caecde5533b48c9a603cbe1c9072eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: <image>\n",
      "Please describe the image in detail.\n",
      "Assistant: The image features an armchair with a bold, striped upholstery. The fabric consists of horizontal stripes in multiple colors including blue, green, red, orange, and beige. The design is reminiscent of a chevron pattern, characteristic of classic American décor. The frame of the chair has dark wooden legs, providing a solid base that contrasts with the vibrant stripes. The chair is placed against a neutral, solid-colored background that highlights its design and colors. The overall aesthetic suggests a blend of traditional and modern styles, making it suitable for various interior design purposes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "# If you want to load a model using multiple GPUs, please refer to the `Multiple GPUs` section.\n",
    "path = 'OpenGVLab/InternVL2-2B'\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True).eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 1.29 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Sofa\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"White\",\n",
      "    \"material\": \"Cotton or microfiber fabric\",\n",
      "    \"shape\": \"L-shaped\",\n",
      "    \"size\": \"Medium-sized\",\n",
      "    \"details\": \"N/A\"\n",
      "}\n",
      "Processing time: 1.68 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Chair\",\n",
      "    \"style\": \"Traditional\",\n",
      "    \"color\": \"White, dark blue, brown, yellow, green, and grey\",\n",
      "    \"material\": \"Fabric (possibly fabric or velvet)\",\n",
      "    \"shape\": \"Rectangular\",\n",
      "    \"size\": \"Large\",\n",
      "    \"details\": \"Plaid pattern on the seat and backrest with vertical stripes\"\n",
      "}\n",
      "Processing time: 1.28 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Table\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Dark gray\",\n",
      "    \"material\": \"Wood and Metal\",\n",
      "    \"shape\": \"Rectangular\",\n",
      "    \"size\": \"Medium\",\n",
      "    \"details\": \"Plain\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Processing time: 1.69 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Sofa\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Orange\",\n",
      "    \"material\": \"Fabric\",\n",
      "    \"shape\": \"Couch\",\n",
      "    \"size\": \"Large\",\n",
      "    \"details\": \"Standard, modular design with a tufted top, modern design, and orange fabric, low-profile legs\",\n",
      "    \"condition\": \"Refurbished\"\n",
      "}\n",
      "Processing time: 1.25 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"table\",\n",
      "    \"style\": \"modern\",\n",
      "    \"color\": \"white\",\n",
      "    \"material\": \"marble\",\n",
      "    \"shape\": \"round\",\n",
      "    \"size\": \"medium\",\n",
      "    \"details\": \"marble surface\",\n",
      "    \"condition\": \"new\n",
      "}\n",
      "Processing time: 1.22 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Chair\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Orange\",\n",
      "    \"material\": \"Velvet\",\n",
      "    \"shape\": \"Rectangular\",\n",
      "    \"size\": \"Large\",\n",
      "    \"details\": \"Solid color with a simple design\"\n",
      "}\n",
      "Processing time: 1.29 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Table\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Blue\",\n",
      "    \"material\": \"Metal\",\n",
      "    \"shape\": \"Round\",\n",
      "    \"size\": \"Small\",\n",
      "    \"details\": \"Round legs, minimalist design, smooth, glossy finish\"\n",
      "}\n",
      "Processing time: 1.01 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"N/A\",\n",
      "    \"style\": \"modern\",\n",
      "    \"color\": \"white\",\n",
      "    \"material\": \"wood\",\n",
      "    \"shape\": \"rectangle\",\n",
      "    \"size\": \"medium\",\n",
      "    \"details\": \"N/A\"\n",
      "}\n",
      "Processing time: 1.67 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Table\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Brown\",\n",
      "    \"material\": \"Wood\",\n",
      "    \"shape\": \"Rectangular\",\n",
      "    \"size\": \"Small\",\n",
      "    \"details\": {\n",
      "        \"square table with legs and drawer pull\", \n",
      "        \"beveled edges\",\n",
      "        \"matte finish\"\n",
      "    },\n",
      "    \"condition\": \"Good\"\n",
      "}\n",
      "Processing time: 1.12 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"N/A\",\n",
      "    \"style\": \"N/A\",\n",
      "    \"color\": \"White\",\n",
      "    \"material\": \"N/A\",\n",
      "    \"shape\": \"N/A\",\n",
      "    \"size\": \"Large\",\n",
      "    \"details\": \"N/A\"\n",
      "}\n",
      "Processing time: 1.44 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Seating section\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"Gray\",\n",
      "    \"material\": \"Seat upholstery, metal frame\",\n",
      "    \"shape\": \"Square\",\n",
      "    \"size\": \"Medium\",\n",
      "    \"details\": \"Radiant modern design with thick padded armrests.\"\n",
      "}\n",
      "Processing time: 1.46 seconds\n",
      "User: <image>\n",
      "Describe the furniture in the image using the following JSON structure. \n",
      "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
      "                                    {\n",
      "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
      "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
      "                                        \"color\": \"Main color\",\n",
      "                                        \"material\": \"Primary material\",\n",
      "                                        \"shape\": \"General shape\",\n",
      "                                        \"size\": \"Size category (small, medium, large)\",\n",
      "                                        \"details\": \"Any decorative features\"\n",
      "                                        \"condition\": \"Apparent condition if relevant\"\n",
      "                                    }\n",
      "Assistant: {\n",
      "    \"type\": \"Sofa\",\n",
      "    \"style\": \"Modern\",\n",
      "    \"color\": \"White\",\n",
      "    \"material\": \"Cotton fabric\",\n",
      "    \"shape\": \"L-shaped\",\n",
      "    \"size\": \"Large\",\n",
      "    \"details\": \"Solid color, minimalist design, comfortable sitting posture\",\n",
      "    \"condition\": \"New\"\n",
      "}\n",
      "Avg time of interface: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "image_folder = \"/home/s464915/future-designer/experiments/images\"\n",
    "\n",
    "times = []\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        # set the max number of tiles in `max_num`\n",
    "        pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "        generation_config = dict(max_new_tokens=100, do_sample=True)\n",
    "\n",
    "        # single-image multi-round conversation (单图多轮对话)\n",
    "        question = '''<image>\\nDescribe the furniture in the image using the following JSON structure. \n",
    "                                                        Use only one word be really specific. If any field is not applicable or cannot be determined, use \"N/A\".\n",
    "                                    {\n",
    "                                        \"type\": \"Main furniture type (e.g., chair, table, sofa)\",\n",
    "                                        \"style\": \"Overall style (e.g., modern, traditional, rustic)\",\n",
    "                                        \"color\": \"Main color\",\n",
    "                                        \"material\": \"Primary material\",\n",
    "                                        \"shape\": \"General shape\",\n",
    "                                        \"size\": \"Size category (small, medium, large)\",\n",
    "                                        \"details\": \"Any decorative features\"\n",
    "                                        \"condition\": \"Apparent condition if relevant\"\n",
    "                                    }'''\n",
    "\n",
    "        start_time = time.time()\n",
    "        response, history = model.chat(tokenizer, pixel_values, question, generation_config, history=None, return_history=True)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate and print the processing time\n",
    "        processing_time = end_time - start_time\n",
    "        times.append(processing_time)\n",
    "\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "\n",
    "        print(f'User: {question}\\nAssistant: {response}')\n",
    "\n",
    "print(f'Avg time of interface: {sum(times)/len(times):.2f} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
